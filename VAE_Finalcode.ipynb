{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_Finalcode.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3m60BGtH6Dn",
        "outputId": "30f1de43-8a3a-4df2-809d-e3eedfceb806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNdBMBbKHxhq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class AutoRec(object):\n",
        "\n",
        "    def __init__(self, visibleDimensions, epochs=3, hiddenDimensions=50, learningRate=0.1, batchSize=100):\n",
        "\n",
        "        self.visibleDimensions = visibleDimensions\n",
        "        self.epochs = epochs\n",
        "        self.hiddenDimensions = hiddenDimensions\n",
        "        self.learningRate = learningRate\n",
        "        self.batchSize = batchSize\n",
        "        self.optimizer = tf.keras.optimizers.RMSprop(self.learningRate)\n",
        "\n",
        "\n",
        "    def Train(self, X):\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(0, X.shape[0], self.batchSize):\n",
        "                epochX = X[i:i+self.batchSize]\n",
        "                self.run_optimization(epochX)\n",
        "\n",
        "\n",
        "            print(\"Trained epoch \", epoch)\n",
        "\n",
        "    def GetRecommendations(self, inputUser):\n",
        "\n",
        "        # Feed through a single user and return predictions from the output layer.\n",
        "        rec = self.neural_net(inputUser)\n",
        "\n",
        "        # It is being used as the return type is Eager Tensor.\n",
        "        return rec[0]\n",
        "\n",
        "\n",
        "    def neural_net(self, inputUser):\n",
        "\n",
        "        #tf.set_random_seed(0)\n",
        "\n",
        "        # Create varaibles for weights for the encoding (visible->hidden) and decoding (hidden->output) stages, randomly initialized\n",
        "        self.weights = {\n",
        "            'h1': tf.Variable(tf.random.normal([self.visibleDimensions, self.hiddenDimensions])),\n",
        "            'out': tf.Variable(tf.random.normal([self.hiddenDimensions, self.visibleDimensions]))\n",
        "            }\n",
        "\n",
        "        # Create biases\n",
        "        self.biases = {\n",
        "            'b1': tf.Variable(tf.random.normal([self.hiddenDimensions])),\n",
        "            'out': tf.Variable(tf.random.normal([self.visibleDimensions]))\n",
        "            }\n",
        "\n",
        "        # Create the input layer\n",
        "        self.inputLayer = inputUser\n",
        "\n",
        "        # hidden layer\n",
        "        hidden = tf.nn.sigmoid(tf.add(tf.matmul(self.inputLayer, self.weights['h1']), self.biases['b1']))\n",
        "\n",
        "        # output layer for our predictions.\n",
        "        self.outputLayer = tf.nn.sigmoid(tf.add(tf.matmul(hidden, self.weights['out']), self.biases['out']))\n",
        "\n",
        "        return self.outputLayer\n",
        "\n",
        "    def run_optimization(self, inputUser):\n",
        "        with tf.GradientTape() as g:\n",
        "            pred = self.neural_net(inputUser)\n",
        "            loss = tf.keras.losses.MSE(inputUser, pred)\n",
        "\n",
        "        trainable_variables = list(self.weights.values()) + list(self.biases.values())\n",
        "\n",
        "        gradients = g.gradient(loss, trainable_variables)\n",
        "\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise\n",
        "from surprise import AlgoBase\n",
        "from surprise import PredictionImpossible\n",
        "import numpy as np\n",
        "\n",
        "class AutoRecAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, epochs=3, hiddenDim=100, learningRate=0.01, batchSize=100, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.epochs = epochs\n",
        "        self.hiddenDim = hiddenDim\n",
        "        self.learningRate = learningRate\n",
        "        self.batchSize = batchSize\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        numUsers = trainset.n_users\n",
        "        numItems = trainset.n_items\n",
        "\n",
        "        trainingMatrix = np.zeros([numUsers, numItems], dtype=np.float32)\n",
        "\n",
        "        for (uid, iid, rating) in trainset.all_ratings():\n",
        "            trainingMatrix[int(uid), int(iid)] = rating / 5.0\n",
        "\n",
        "        # Create an RBM with (num items * rating values) visible nodes\n",
        "        autoRec = AutoRec(trainingMatrix.shape[1], hiddenDimensions=self.hiddenDim, learningRate=self.learningRate, batchSize=self.batchSize, epochs=self.epochs)\n",
        "        autoRec.Train(trainingMatrix)\n",
        "\n",
        "        self.predictedRatings = np.zeros([numUsers, numItems], dtype=np.float32)\n",
        "\n",
        "        for uiid in range(trainset.n_users):\n",
        "            if (uiid % 50 == 0):\n",
        "                print(\"Processing user \", uiid)\n",
        "            recs = autoRec.GetRecommendations([trainingMatrix[uiid]])\n",
        "\n",
        "            for itemID, rec in enumerate(recs):\n",
        "                self.predictedRatings[uiid, itemID] = rec * 5.0\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "\n",
        "        rating = self.predictedRatings[u, i]\n",
        "\n",
        "        if (rating < 0.001):\n",
        "            raise PredictionImpossible('No valid prediction exists.')\n",
        "\n",
        "        return rating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lN8S34eIKeT",
        "outputId": "0c4d5d4d-7949-4081-a5fd-6b5f7473007d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1630179 sha256=f8f0e98012cbfe45540c6e67631123459abf7cb7a827bb9792bda64111df6674\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "class MovieLens:\n",
        "\n",
        "    movieID_to_name = {}\n",
        "    name_to_movieID = {}\n",
        "    ratingsPath = '/content/drive/MyDrive/Colab_Notebooks/ml20/ratings.csv'\n",
        "    moviesPath = '/content/drive/MyDrive/Colab_Notebooks/ml20/movies.csv'\n",
        "    def loadMovieLensLatestSmall(self):\n",
        "\n",
        "        # Look for files relative to the directory we are running from\n",
        "        os.chdir(os.path.dirname(sys.argv[0]))\n",
        "\n",
        "        ratingsDataset = 0\n",
        "        self.movieID_to_name = {}\n",
        "        self.name_to_movieID = {}\n",
        "\n",
        "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "\n",
        "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
        "\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "                movieReader = csv.reader(csvfile)\n",
        "                next(movieReader)  #Skip header line\n",
        "                for row in movieReader:\n",
        "                    movieID = int(row[0])\n",
        "                    movieName = row[1]\n",
        "                    self.movieID_to_name[movieID] = movieName\n",
        "                    self.name_to_movieID[movieName] = movieID\n",
        "\n",
        "        return ratingsDataset\n",
        "\n",
        "    def getUserRatings(self, user):\n",
        "        userRatings = []\n",
        "        hitUser = False\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                userID = int(row[0])\n",
        "                if (user == userID):\n",
        "                    movieID = int(row[1])\n",
        "                    rating = float(row[2])\n",
        "                    userRatings.append((movieID, rating))\n",
        "                    hitUser = True\n",
        "                if (hitUser and (user != userID)):\n",
        "                    break\n",
        "\n",
        "        return userRatings\n",
        "\n",
        "    def getPopularityRanks(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = defaultdict(int)\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                movieID = int(row[1])\n",
        "                ratings[movieID] += 1\n",
        "        rank = 1\n",
        "        for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[movieID] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "    def getGenres(self):\n",
        "        genres = defaultdict(list)\n",
        "        genreIDs = {}\n",
        "        maxGenreID = 0\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)  #Skip header line\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                genreList = row[2].split('|')\n",
        "                genreIDList = []\n",
        "                for genre in genreList:\n",
        "                    if genre in genreIDs:\n",
        "                        genreID = genreIDs[genre]\n",
        "                    else:\n",
        "                        genreID = maxGenreID\n",
        "                        genreIDs[genre] = genreID\n",
        "                        maxGenreID += 1\n",
        "                    genreIDList.append(genreID)\n",
        "                genres[movieID] = genreIDList\n",
        "        # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
        "        for (movieID, genreIDList) in genres.items():\n",
        "            bitfield = [0] * maxGenreID\n",
        "            for genreID in genreIDList:\n",
        "                bitfield[genreID] = 1\n",
        "            genres[movieID] = bitfield\n",
        "\n",
        "        return genres\n",
        "\n",
        "    def getYears(self):\n",
        "        p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
        "        years = defaultdict(int)\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                title = row[1]\n",
        "                m = p.search(title)\n",
        "                year = m.group(1)\n",
        "                if year:\n",
        "                    years[movieID] = int(year)\n",
        "        return years\n",
        "\n",
        "    def getMiseEnScene(self):\n",
        "        mes = defaultdict(list)\n",
        "        with open(\"LLVisualFeatures13K_Log.csv\", newline='') as csvfile:\n",
        "            mesReader = csv.reader(csvfile)\n",
        "            next(mesReader)\n",
        "            for row in mesReader:\n",
        "                movieID = int(row[0])\n",
        "                avgShotLength = float(row[1])\n",
        "                meanColorVariance = float(row[2])\n",
        "                stddevColorVariance = float(row[3])\n",
        "                meanMotion = float(row[4])\n",
        "                stddevMotion = float(row[5])\n",
        "                meanLightingKey = float(row[6])\n",
        "                numShots = float(row[7])\n",
        "                mes[movieID] = [avgShotLength, meanColorVariance, stddevColorVariance,\n",
        "                   meanMotion, stddevMotion, meanLightingKey, numShots]\n",
        "        return mes\n",
        "\n",
        "    def getMovieName(self, movieID):\n",
        "        if movieID in self.movieID_to_name:\n",
        "            return self.movieID_to_name[movieID]\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    def getMovieID(self, movieName):\n",
        "        if movieName in self.name_to_movieID:\n",
        "            return self.name_to_movieID[movieName]\n",
        "        else:\n",
        "            return 0"
      ],
      "metadata": {
        "id": "82hRqVKvIKhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "from surprise import KNNBaseline\n",
        "\n",
        "class EvaluationData:\n",
        "\n",
        "    def __init__(self, data, popularityRankings):\n",
        "\n",
        "        self.rankings = popularityRankings\n",
        "\n",
        "        #Build a full training set for evaluating overall properties\n",
        "        self.fullTrainSet = data.build_full_trainset()\n",
        "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
        "\n",
        "        #Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
        "\n",
        "        #Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
        "        #And build an anti-test-set for building predictions\n",
        "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
        "        for train, test in LOOCV.split(data):\n",
        "            self.LOOCVTrain = train\n",
        "            self.LOOCVTest = test\n",
        "\n",
        "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
        "\n",
        "        #Compute similarty matrix between items so we can measure diversity\n",
        "        sim_options = {'name': 'cosine', 'user_based': False}\n",
        "        self.simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "        self.simsAlgo.fit(self.fullTrainSet)\n",
        "\n",
        "    def GetFullTrainSet(self):\n",
        "        return self.fullTrainSet\n",
        "\n",
        "    def GetFullAntiTestSet(self):\n",
        "        return self.fullAntiTestSet\n",
        "\n",
        "    def GetAntiTestSetForUser(self, testSubject):\n",
        "        trainset = self.fullTrainSet\n",
        "        fill = trainset.global_mean\n",
        "        anti_testset = []\n",
        "        u = trainset.to_inner_uid(str(testSubject))\n",
        "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
        "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
        "                                 i in trainset.all_items() if\n",
        "                                 i not in user_items]\n",
        "        return anti_testset\n",
        "\n",
        "    def GetTrainSet(self):\n",
        "        return self.trainSet\n",
        "\n",
        "    def GetTestSet(self):\n",
        "        return self.testSet\n",
        "\n",
        "    def GetLOOCVTrainSet(self):\n",
        "        return self.LOOCVTrain\n",
        "\n",
        "    def GetLOOCVTestSet(self):\n",
        "        return self.LOOCVTest\n",
        "\n",
        "    def GetLOOCVAntiTestSet(self):\n",
        "        return self.LOOCVAntiTestSet\n",
        "\n",
        "    def GetSimilarities(self):\n",
        "        return self.simsAlgo\n",
        "\n",
        "    def GetPopularityRankings(self):\n",
        "        return self.rankings"
      ],
      "metadata": {
        "id": "AB17l80mIKrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "\n",
        "    algorithms = []\n",
        "\n",
        "    def __init__(self, dataset, rankings):\n",
        "        ed = EvaluationData(dataset, rankings)\n",
        "        self.dataset = ed\n",
        "\n",
        "    def AddAlgorithm(self, algorithm, name):\n",
        "        alg = EvaluatedAlgorithm(algorithm, name)\n",
        "        self.algorithms.append(alg)\n",
        "\n",
        "    def Evaluate(self, doTopN):\n",
        "        results = {}\n",
        "        for algorithm in self.algorithms:\n",
        "            print(\"Evaluating \", algorithm.GetName(), \"...\")\n",
        "            results[algorithm.GetName()] = algorithm.Evaluate(self.dataset, doTopN)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\")\n",
        "\n",
        "        if (doTopN):\n",
        "            print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\n",
        "                    \"Algorithm\", \"RMSE\", \"MAE\", \"HR\", \"cHR\", \"ARHR\", \"Coverage\", \"Diversity\", \"Novelty\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
        "                        name, metrics[\"RMSE\"], metrics[\"MAE\"], metrics[\"HR\"], metrics[\"cHR\"], metrics[\"ARHR\"],\n",
        "                                      metrics[\"Coverage\"], metrics[\"Diversity\"], metrics[\"Novelty\"]))\n",
        "        else:\n",
        "            print(\"{:<10} {:<10} {:<10}\".format(\"Algorithm\", \"RMSE\", \"MAE\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f}\".format(name, metrics[\"RMSE\"], metrics[\"MAE\"]))\n",
        "\n",
        "        print(\"\\nLegend:\\n\")\n",
        "        print(\"RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\")\n",
        "        print(\"MAE:       Mean Absolute Error. Lower values mean better accuracy.\")\n",
        "        if (doTopN):\n",
        "            print(\"HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\")\n",
        "            print(\"cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\")\n",
        "            print(\"ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\" )\n",
        "            print(\"Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\")\n",
        "            print(\"Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\")\n",
        "            print(\"           for a given user. Higher means more diverse.\")\n",
        "            print(\"Novelty:   Average popularity rank of recommended items. Higher means more novel.\")\n",
        "\n",
        "    def SampleTopNRecs(self, ml, testSubject=85, k=10):\n",
        "\n",
        "        for algo in self.algorithms:\n",
        "            print(\"\\nUsing recommender \", algo.GetName())\n",
        "\n",
        "            print(\"\\nBuilding recommendation model...\")\n",
        "            trainSet = self.dataset.GetFullTrainSet()\n",
        "            algo.GetAlgorithm().fit(trainSet)\n",
        "\n",
        "            print(\"Computing recommendations...\")\n",
        "            testSet = self.dataset.GetAntiTestSetForUser(testSubject)\n",
        "\n",
        "            predictions = algo.GetAlgorithm().test(testSet)\n",
        "\n",
        "            recommendations = []\n",
        "\n",
        "            print (\"\\nWe recommend:\")\n",
        "            for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "                intMovieID = int(movieID)\n",
        "                recommendations.append((intMovieID, estimatedRating))\n",
        "\n",
        "            recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            for ratings in recommendations[:10]:\n",
        "                print(ml.getMovieName(ratings[0]), ratings[1])"
      ],
      "metadata": {
        "id": "sx0fxAAzIKxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "from surprise import accuracy\n",
        "from collections import defaultdict\n",
        "\n",
        "class RecommenderMetrics:\n",
        "\n",
        "    def MAE(predictions):\n",
        "        return accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "    def RMSE(predictions):\n",
        "        return accuracy.rmse(predictions, verbose=False)\n",
        "\n",
        "    def GetTopN(predictions, n=10, minimumRating=0.0):\n",
        "        topN = defaultdict(list)\n",
        "\n",
        "\n",
        "        for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "            if (estimatedRating >= minimumRating):\n",
        "                topN[int(userID)].append((int(movieID), estimatedRating))\n",
        "\n",
        "        for userID, ratings in topN.items():\n",
        "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "            topN[int(userID)] = ratings[:n]\n",
        "\n",
        "        return topN\n",
        "\n",
        "    def HitRate(topNPredicted, leftOutPredictions):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for leftOut in leftOutPredictions:\n",
        "            userID = leftOut[0]\n",
        "            leftOutMovieID = leftOut[1]\n",
        "            # Is it in the predicted top 10 for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == int(movieID)):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits += 1\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Only look at ability to recommend things the users actually liked...\n",
        "            if (actualRating >= ratingCutoff):\n",
        "                # Is it in the predicted top 10 for this user?\n",
        "                hit = False\n",
        "                for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                    if (int(leftOutMovieID) == movieID):\n",
        "                        hit = True\n",
        "                        break\n",
        "                if (hit) :\n",
        "                    hits += 1\n",
        "\n",
        "                total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def RatingHitRate(topNPredicted, leftOutPredictions):\n",
        "        hits = defaultdict(float)\n",
        "        total = defaultdict(float)\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits[actualRating] += 1\n",
        "\n",
        "            total[actualRating] += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        for rating in sorted(hits.keys()):\n",
        "            print (rating, hits[rating] / total[rating])\n",
        "    def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
        "        summation = 0\n",
        "        total = 0\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hitRank = 0\n",
        "            rank = 0\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                rank = rank + 1\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hitRank = rank\n",
        "                    break\n",
        "            if (hitRank > 0) :\n",
        "                summation += 1.0 / hitRank\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        return summation / total\n",
        "\n",
        "    # What percentage of users have at least one \"good\" recommendation\n",
        "    def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
        "        hits = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[userID]:\n",
        "                if (predictedRating >= ratingThreshold):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit):\n",
        "                hits += 1\n",
        "\n",
        "        return hits / numUsers\n",
        "\n",
        "    def Diversity(topNPredicted, simsAlgo):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        simsMatrix = simsAlgo.compute_similarities()\n",
        "        for userID in topNPredicted.keys():\n",
        "            pairs = itertools.combinations(topNPredicted[userID], 2)\n",
        "            for pair in pairs:\n",
        "                movie1 = pair[0][0]\n",
        "                movie2 = pair[1][0]\n",
        "                innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
        "                innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
        "                similarity = simsMatrix[innerID1][innerID2]\n",
        "                total += similarity\n",
        "                n += 1\n",
        "\n",
        "        if (n > 0):\n",
        "            S = total / n\n",
        "            return (1-S)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def Novelty(topNPredicted, rankings):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            for rating in topNPredicted[userID]:\n",
        "                movieID = rating[0]\n",
        "                rank = rankings[movieID]\n",
        "                total += rank\n",
        "                n += 1\n",
        "        return total / n"
      ],
      "metadata": {
        "id": "_HdXNw_0JpRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluatedAlgorithm:\n",
        "\n",
        "    def __init__(self, algorithm, name):\n",
        "        self.algorithm = algorithm\n",
        "        self.name = name\n",
        "\n",
        "    def Evaluate(self, evaluationData, doTopN, n=10, verbose=True):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "        if (verbose):\n",
        "            print(\"Evaluating accuracy...\")\n",
        "        self.algorithm.fit(evaluationData.GetTrainSet())\n",
        "        predictions = self.algorithm.test(evaluationData.GetTestSet())\n",
        "        metrics[\"RMSE\"] = RecommenderMetrics.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = RecommenderMetrics.MAE(predictions)\n",
        "\n",
        "        if (doTopN):\n",
        "            # Evaluate top-10 with Leave One Out testing\n",
        "            if (verbose):\n",
        "                print(\"Evaluating top-N with leave-one-out...\")\n",
        "            self.algorithm.fit(evaluationData.GetLOOCVTrainSet())\n",
        "            leftOutPredictions = self.algorithm.test(evaluationData.GetLOOCVTestSet())\n",
        "            # Build predictions for all ratings not in the training set\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetLOOCVAntiTestSet())\n",
        "            # Compute top 10 recs for each user\n",
        "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Computing hit-rate and rank metrics...\")\n",
        "            # See how often we recommended a movie the user actually rated\n",
        "            metrics[\"HR\"] = RecommenderMetrics.HitRate(topNPredicted, leftOutPredictions)\n",
        "            # See how often we recommended a movie the user actually liked\n",
        "            metrics[\"cHR\"] = RecommenderMetrics.CumulativeHitRate(topNPredicted, leftOutPredictions)\n",
        "            # Compute ARHR\n",
        "            metrics[\"ARHR\"] = RecommenderMetrics.AverageReciprocalHitRank(topNPredicted, leftOutPredictions)\n",
        "\n",
        "            #Evaluate properties of recommendations on full training set\n",
        "            if (verbose):\n",
        "                print(\"Computing recommendations with full data set...\")\n",
        "            self.algorithm.fit(evaluationData.GetFullTrainSet())\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetFullAntiTestSet())\n",
        "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Analyzing coverage, diversity, and novelty...\")\n",
        "            # Print user coverage with a minimum predicted rating of 4.0:\n",
        "            metrics[\"Coverage\"] = RecommenderMetrics.UserCoverage(  topNPredicted,\n",
        "                                                                   evaluationData.GetFullTrainSet().n_users,\n",
        "                                                                   ratingThreshold=4.0)\n",
        "            # Measure diversity of recommendations:\n",
        "            metrics[\"Diversity\"] = RecommenderMetrics.Diversity(topNPredicted, evaluationData.GetSimilarities())\n",
        "\n",
        "            # Measure novelty (average popularity rank of recommendations):\n",
        "            metrics[\"Novelty\"] = RecommenderMetrics.Novelty(topNPredicted,\n",
        "                                                            evaluationData.GetPopularityRankings())\n",
        "\n",
        "        if (verbose):\n",
        "            print(\"Analysis complete.\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "\n",
        "    def GetAlgorithm(self):\n",
        "        return self.algorithm"
      ],
      "metadata": {
        "id": "q8toSExAJpd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import NormalPredictor\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "#Autoencoder\n",
        "AutoRecSys = AutoRecAlgorithm()\n",
        "evaluator.AddAlgorithm(AutoRecSys, \"AutoRec\")\n",
        "\n",
        "# Just make random recommendations\n",
        "Random = NormalPredictor()\n",
        "evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "# Fight!\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FlNn1nGiKB4h",
        "outputId": "175b7ba1-7936-4989-c964-229da7c0f19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  AutoRec ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Processing user  0\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  AutoRec ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Processing user  0\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  AutoRec ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Processing user  0\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  AutoRec ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Processing user  0\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  AutoRec ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Processing user  0\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "AutoRec    0.2784     0.2750    \n",
            "Random     0.2103     0.1622    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  AutoRec\n",
            "\n",
            "Building recommendation model...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Processing user  0\n",
            "Computing recommendations...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/trainset.py\u001b[0m in \u001b[0;36mto_inner_uid\u001b[0;34m(self, ruid)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw2inner_id_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mruid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '85'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-572c7bd4cb62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampleTopNRecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-08ddd4f71699>\u001b[0m in \u001b[0;36mSampleTopNRecs\u001b[0;34m(self, ml, testSubject, k)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing recommendations...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mtestSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAntiTestSetForUser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-434ab70daa4e>\u001b[0m in \u001b[0;36mGetAntiTestSetForUser\u001b[0;34m(self, testSubject)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0manti_testset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_inner_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0muser_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/trainset.py\u001b[0m in \u001b[0;36mto_inner_uid\u001b[0;34m(self, ruid)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError('User ' + str(ruid) +\n\u001b[0;32m--> 108\u001b[0;31m                              ' is not part of the trainset.')\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_raw_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miuid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: User 85 is not part of the trainset."
          ]
        }
      ]
    }
  ]
}