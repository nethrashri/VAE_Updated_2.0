{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se901OuwQe8d",
        "outputId": "efeb080d-4f05-4a04-c1e9-44fafab19375"
      },
      "id": "se901OuwQe8d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import tensorflow as tf\n",
        "#from tensorflow.contrib.layers import apply_regularization, l2_regularizer #Paquetes eliminados\n",
        "\n",
        "import bottleneck as bn\n",
        "\n",
        "import os\n"
      ],
      "metadata": {
        "id": "wFO6m3pSQc1L"
      },
      "id": "wFO6m3pSQc1L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cab06cf8",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:14.022270Z",
          "iopub.status.busy": "2021-11-16T19:32:14.021623Z",
          "iopub.status.idle": "2021-11-16T19:32:36.689824Z",
          "shell.execute_reply": "2021-11-16T19:32:36.689189Z",
          "shell.execute_reply.started": "2021-11-16T18:36:35.661902Z"
        },
        "papermill": {
          "duration": 22.725947,
          "end_time": "2021-11-16T19:32:36.689962",
          "exception": false,
          "start_time": "2021-11-16T19:32:13.964015",
          "status": "completed"
        },
        "tags": [],
        "id": "cab06cf8"
      },
      "outputs": [],
      "source": [
        "#Cargando datos\n",
        "raw_data = pd.read_csv(\"/content/drive/MyDrive/Colab_Notebooks/ml-20m/ml-20m/ratings.csv\", header = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e16517",
      "metadata": {
        "papermill": {
          "duration": 0.051818,
          "end_time": "2021-11-16T19:32:36.794138",
          "exception": false,
          "start_time": "2021-11-16T19:32:36.742320",
          "status": "completed"
        },
        "tags": [],
        "id": "78e16517"
      },
      "source": [
        "Visualización de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5269ed68",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:36.902280Z",
          "iopub.status.busy": "2021-11-16T19:32:36.901688Z",
          "iopub.status.idle": "2021-11-16T19:32:36.919938Z",
          "shell.execute_reply": "2021-11-16T19:32:36.920531Z",
          "shell.execute_reply.started": "2021-11-16T18:36:58.805519Z"
        },
        "papermill": {
          "duration": 0.074206,
          "end_time": "2021-11-16T19:32:36.920700",
          "exception": false,
          "start_time": "2021-11-16T19:32:36.846494",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5269ed68",
        "outputId": "544d461b-4f36-4675-f65a-1f55c816b221"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1        2     3.5  1112486027\n",
              "1       1       29     3.5  1112484676\n",
              "2       1       32     3.5  1112484819\n",
              "3       1       47     3.5  1112484727\n",
              "4       1       50     3.5  1112484580"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa5d61a7-4d3c-43e0-a7d1-d86a5d2e0897\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112486027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa5d61a7-4d3c-43e0-a7d1-d86a5d2e0897')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa5d61a7-4d3c-43e0-a7d1-d86a5d2e0897 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa5d61a7-4d3c-43e0-a7d1-d86a5d2e0897');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389337ca",
      "metadata": {
        "papermill": {
          "duration": 0.053577,
          "end_time": "2021-11-16T19:32:37.027913",
          "exception": false,
          "start_time": "2021-11-16T19:32:36.974336",
          "status": "completed"
        },
        "tags": [],
        "id": "389337ca"
      },
      "source": [
        "Binarizando datos (Tomando los datos con rating >= 4).\n",
        "\n",
        "Se tiene una base de datos de calificaciones desde 0.5 a 5.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "846b29c3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:37.137086Z",
          "iopub.status.busy": "2021-11-16T19:32:37.136449Z",
          "iopub.status.idle": "2021-11-16T19:32:49.650078Z",
          "shell.execute_reply": "2021-11-16T19:32:49.649470Z",
          "shell.execute_reply.started": "2021-11-16T18:36:58.828564Z"
        },
        "papermill": {
          "duration": 12.569456,
          "end_time": "2021-11-16T19:32:49.650211",
          "exception": false,
          "start_time": "2021-11-16T19:32:37.080755",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "846b29c3",
        "outputId": "ce53bf21-4d25-49c0-a121-b578a23fc3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Ratings < 0.5:  0\n",
            "# Ratings = 0.5:  239125\n",
            "# Ratings > 3.5:  9995410\n",
            "# Ratings = 4.5:  1534824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  rating   timestamp\n",
              "6        1      151     4.0  1094785734\n",
              "7        1      223     4.0  1112485573\n",
              "8        1      253     4.0  1112484940\n",
              "9        1      260     4.0  1112484826\n",
              "10       1      293     4.0  1112484703"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10bf8d57-b877-4403-b70e-ac397b40eafb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1094785734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>223</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112485573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>253</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10bf8d57-b877-4403-b70e-ac397b40eafb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10bf8d57-b877-4403-b70e-ac397b40eafb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10bf8d57-b877-4403-b70e-ac397b40eafb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(\"# Ratings < 0.5: \",sum(raw_data['rating']<0.5))\n",
        "print(\"# Ratings = 0.5: \",sum(raw_data['rating']==0.5))\n",
        "print(\"# Ratings > 3.5: \",sum(raw_data['rating']>3.5))\n",
        "print(\"# Ratings = 4.5: \",sum(raw_data['rating']==4.5))\n",
        "\n",
        "raw_data = raw_data[raw_data['rating']>3.5]\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3941e64",
      "metadata": {
        "papermill": {
          "duration": 0.059148,
          "end_time": "2021-11-16T19:32:49.763783",
          "exception": false,
          "start_time": "2021-11-16T19:32:49.704635",
          "status": "completed"
        },
        "tags": [],
        "id": "b3941e64"
      },
      "source": [
        "# **Procedimiento de división de datos**\n",
        "* Seleccionar 10K usuarios como usuarios excluidos, 10K usuarios como usuarios de validación y el resto de los usuarios para el entrenamiento.\n",
        "* Utilizar todos los ítems de los usuarios de entrenamiento como conjunto de ítems.\n",
        "* Para cada usuario de validación y de prueba, submuestrear el 80% como datos plegables y el resto para la predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5681c53",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:49.898876Z",
          "iopub.status.busy": "2021-11-16T19:32:49.898135Z",
          "iopub.status.idle": "2021-11-16T19:32:49.904000Z",
          "shell.execute_reply": "2021-11-16T19:32:49.904493Z",
          "shell.execute_reply.started": "2021-11-16T18:37:11.868816Z"
        },
        "papermill": {
          "duration": 0.085941,
          "end_time": "2021-11-16T19:32:49.904660",
          "exception": false,
          "start_time": "2021-11-16T19:32:49.818719",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5681c53",
        "outputId": "6c28ee31-3b37-4de1-a5a2-41e3cfc75101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method GroupBy.size of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7ff7bde918d0>>\n"
          ]
        }
      ],
      "source": [
        "#Función que cuenta el número de determinados ítems agrupados \n",
        "print(raw_data[['movieId']].groupby('movieId', as_index=False).size)\n",
        "def get_count( data, item ):\n",
        "    playcount_groupbyid = data[[item]].groupby(item, as_index=False) #Agrupa por ítems y cuenta el # de c/grupo\n",
        "    count = playcount_groupbyid.size()['size']\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04b96882",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:50.018995Z",
          "iopub.status.busy": "2021-11-16T19:32:50.018307Z",
          "iopub.status.idle": "2021-11-16T19:32:50.259304Z",
          "shell.execute_reply": "2021-11-16T19:32:50.258732Z",
          "shell.execute_reply.started": "2021-11-16T18:37:11.895139Z"
        },
        "papermill": {
          "duration": 0.299276,
          "end_time": "2021-11-16T19:32:50.259459",
          "exception": false,
          "start_time": "2021-11-16T19:32:49.960183",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04b96882",
        "outputId": "9b1fe4a3-817f-41a7-cae0-ff09d166a90e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          88\n",
              "1          43\n",
              "2         145\n",
              "3          16\n",
              "4          50\n",
              "         ... \n",
              "138282     27\n",
              "138283     86\n",
              "138284      5\n",
              "138285     61\n",
              "138286    301\n",
              "Name: size, Length: 138287, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "get_count(raw_data, 'userId')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d1ec3c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:50.373647Z",
          "iopub.status.busy": "2021-11-16T19:32:50.373005Z",
          "iopub.status.idle": "2021-11-16T19:32:50.379434Z",
          "shell.execute_reply": "2021-11-16T19:32:50.379915Z",
          "shell.execute_reply.started": "2021-11-16T18:37:12.077352Z"
        },
        "papermill": {
          "duration": 0.065339,
          "end_time": "2021-11-16T19:32:50.380120",
          "exception": false,
          "start_time": "2021-11-16T19:32:50.314781",
          "status": "completed"
        },
        "tags": [],
        "id": "75d1ec3c"
      },
      "outputs": [],
      "source": [
        "#Función de tripletas filtradas (datos, conteo de usuarios y conteo de ítems)\n",
        "def filter_triplets( data, min_uc = 5, min_sc = 5 ):\n",
        "    #Considerando tripletas solo para ítems que han sido seleccionadas por al menos min_sc usuarios\n",
        "    if min_sc > 0:\n",
        "        item_count = get_count( data, 'movieId')\n",
        "        data = data[ data[ 'movieId' ].isin(item_count.index[ item_count >= min_sc ] ) ]  #i.sin donde see encuentran los valores en el data frame\n",
        "    #Considerando tripletas para usuarios que interactuaron con al menos min_uc ítems                                         \n",
        "    if min_uc > 0:\n",
        "        user_count = get_count( data, 'userId' )\n",
        "        data = data[ data[ 'userId' ].isin(user_count.index[ user_count >= min_uc ] ) ]  #i.sin donde see encuentran los valores en el data frame                                    \n",
        "    #Actualizando el contador de items y de usuarios despues de los filtros\n",
        "    item_count = get_count( data, 'movieId' )\n",
        "    user_count = get_count( data, 'userId' )\n",
        "    return data, user_count, item_count \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13b41467",
      "metadata": {
        "papermill": {
          "duration": 0.0563,
          "end_time": "2021-11-16T19:32:50.492669",
          "exception": false,
          "start_time": "2021-11-16T19:32:50.436369",
          "status": "completed"
        },
        "tags": [],
        "id": "13b41467"
      },
      "source": [
        "Considerando ítems que fueron calificados por al menos 5 usuarios y usuarios que calificaron al menos 5 películas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "126a5055",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:50.607206Z",
          "iopub.status.busy": "2021-11-16T19:32:50.606616Z",
          "iopub.status.idle": "2021-11-16T19:32:52.442006Z",
          "shell.execute_reply": "2021-11-16T19:32:52.442530Z",
          "shell.execute_reply.started": "2021-11-16T18:37:12.087478Z"
        },
        "papermill": {
          "duration": 1.894645,
          "end_time": "2021-11-16T19:32:52.442720",
          "exception": false,
          "start_time": "2021-11-16T19:32:50.548075",
          "status": "completed"
        },
        "tags": [],
        "id": "126a5055"
      },
      "outputs": [],
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93a4798e",
      "metadata": {
        "papermill": {
          "duration": 0.054815,
          "end_time": "2021-11-16T19:32:52.553358",
          "exception": false,
          "start_time": "2021-11-16T19:32:52.498543",
          "status": "completed"
        },
        "tags": [],
        "id": "93a4798e"
      },
      "source": [
        "**Calculando 'dispersión'**\n",
        "* Se calcula el numerador de la métrica de dispersión contando el número total de calificaciones contenidas en la matriz de calificaciones.\n",
        "* Se calcula el denominador de la métrica de dispersión multiplicando el número de usuarios por el número de películas en la matriz de clasificación.\n",
        "* Se calcula e imprime la dispersión dividiendo el numerador por el denominador, restando de 1 y multiplicando por 100. Se agrega 1.0 para garantizar que la dispersión se devuelva como un decimal y no como un número entero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13d2815",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:52.669776Z",
          "iopub.status.busy": "2021-11-16T19:32:52.669123Z",
          "iopub.status.idle": "2021-11-16T19:32:52.672500Z",
          "shell.execute_reply": "2021-11-16T19:32:52.671987Z",
          "shell.execute_reply.started": "2021-11-16T18:37:13.632663Z"
        },
        "papermill": {
          "duration": 0.064076,
          "end_time": "2021-11-16T19:32:52.672644",
          "exception": false,
          "start_time": "2021-11-16T19:32:52.608568",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c13d2815",
        "outputId": "6eb9a865-c285-48fe-aa71-86f9bccaafe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Después de los filtros, hay 8323972 eventos de 135308 usuarios y 7567 películas (ítems) (dispersión: 0.813%)\n"
          ]
        }
      ],
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"Después de los filtros, hay %d eventos de %d usuarios y %d películas (ítems) (dispersión: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e0277d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:52.788761Z",
          "iopub.status.busy": "2021-11-16T19:32:52.788118Z",
          "iopub.status.idle": "2021-11-16T19:32:52.791723Z",
          "shell.execute_reply": "2021-11-16T19:32:52.792208Z",
          "shell.execute_reply.started": "2021-11-16T18:37:13.641381Z"
        },
        "papermill": {
          "duration": 0.064288,
          "end_time": "2021-11-16T19:32:52.792364",
          "exception": false,
          "start_time": "2021-11-16T19:32:52.728076",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5e0277d",
        "outputId": "aa906d1d-690d-46bc-edd0-0701bbd7cc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8323972, 4)\n",
            "(7567,)\n",
            "(135308,)\n"
          ]
        }
      ],
      "source": [
        "print(raw_data.shape)\n",
        "print(item_popularity.shape)\n",
        "print(user_activity.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00b306f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:52.910402Z",
          "iopub.status.busy": "2021-11-16T19:32:52.909723Z",
          "iopub.status.idle": "2021-11-16T19:32:52.917340Z",
          "shell.execute_reply": "2021-11-16T19:32:52.917910Z",
          "shell.execute_reply.started": "2021-11-16T18:37:13.659123Z"
        },
        "papermill": {
          "duration": 0.069847,
          "end_time": "2021-11-16T19:32:52.918085",
          "exception": false,
          "start_time": "2021-11-16T19:32:52.848238",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e00b306f",
        "outputId": "f120d8fa-985f-4b22-fefa-19da6f71a883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135308\n"
          ]
        }
      ],
      "source": [
        "#Index único de usuario\n",
        "unique_uid = user_activity.index\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)#permutando los indices de los usuarios\n",
        "unique_uid = unique_uid[idx_perm]\n",
        "print(unique_uid.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36d9324",
      "metadata": {
        "papermill": {
          "duration": 0.056704,
          "end_time": "2021-11-16T19:32:53.031916",
          "exception": false,
          "start_time": "2021-11-16T19:32:52.975212",
          "status": "completed"
        },
        "tags": [],
        "id": "e36d9324"
      },
      "source": [
        "Creando train/validation/test para usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "317a2510",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:53.150923Z",
          "iopub.status.busy": "2021-11-16T19:32:53.150271Z",
          "iopub.status.idle": "2021-11-16T19:32:53.152708Z",
          "shell.execute_reply": "2021-11-16T19:32:53.153194Z",
          "shell.execute_reply.started": "2021-11-16T18:37:13.685847Z"
        },
        "papermill": {
          "duration": 0.065148,
          "end_time": "2021-11-16T19:32:53.153365",
          "exception": false,
          "start_time": "2021-11-16T19:32:53.088217",
          "status": "completed"
        },
        "tags": [],
        "id": "317a2510"
      },
      "outputs": [],
      "source": [
        "n_users = unique_uid.size\n",
        "n_heldout_users = 10000\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)] #135308-20000 = 115308\n",
        "#10000\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] #115308+10000 =125308 \n",
        "#10000\n",
        "te_users = unique_uid[(n_users - n_heldout_users):] #125308 + 10000 = 135308"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827768ef",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:53.268889Z",
          "iopub.status.busy": "2021-11-16T19:32:53.268242Z",
          "iopub.status.idle": "2021-11-16T19:32:53.619909Z",
          "shell.execute_reply": "2021-11-16T19:32:53.619302Z",
          "shell.execute_reply.started": "2021-11-16T18:37:13.691667Z"
        },
        "papermill": {
          "duration": 0.410553,
          "end_time": "2021-11-16T19:32:53.620056",
          "exception": false,
          "start_time": "2021-11-16T19:32:53.209503",
          "status": "completed"
        },
        "tags": [],
        "id": "827768ef"
      },
      "outputs": [],
      "source": [
        "#Seleccionando a todos los usuarios de entrenamiento de nuestros datos\n",
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c1c0ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:53.736222Z",
          "iopub.status.busy": "2021-11-16T19:32:53.735236Z",
          "iopub.status.idle": "2021-11-16T19:32:53.787622Z",
          "shell.execute_reply": "2021-11-16T19:32:53.788152Z",
          "shell.execute_reply.started": "2021-11-16T18:37:14.034549Z"
        },
        "papermill": {
          "duration": 0.112317,
          "end_time": "2021-11-16T19:32:53.788328",
          "exception": false,
          "start_time": "2021-11-16T19:32:53.676011",
          "status": "completed"
        },
        "tags": [],
        "id": "d4c1c0ff"
      },
      "outputs": [],
      "source": [
        "#Películas sin repeticion\n",
        "unique_sid = pd.unique( train_plays[ 'movieId'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb71b95c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:53.904266Z",
          "iopub.status.busy": "2021-11-16T19:32:53.903289Z",
          "iopub.status.idle": "2021-11-16T19:32:53.962793Z",
          "shell.execute_reply": "2021-11-16T19:32:53.963776Z",
          "shell.execute_reply.started": "2021-11-16T18:37:14.081749Z"
        },
        "papermill": {
          "duration": 0.11989,
          "end_time": "2021-11-16T19:32:53.964109",
          "exception": false,
          "start_time": "2021-11-16T19:32:53.844219",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb71b95c",
        "outputId": "996dad3f-7811-47a9-9fbb-4b06cba284ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135308\n",
            "7550\n"
          ]
        }
      ],
      "source": [
        "#Diccionario para usuarios \n",
        "profile2id = dict((pid,i) for (i, pid) in enumerate(unique_uid))\n",
        "print(len(profile2id))\n",
        "#Diccionario para películas (enumero los índices)\n",
        "show2id   = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "print(len(show2id))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a36a6e3f",
      "metadata": {
        "papermill": {
          "duration": 0.057769,
          "end_time": "2021-11-16T19:32:54.080058",
          "exception": false,
          "start_time": "2021-11-16T19:32:54.022289",
          "status": "completed"
        },
        "tags": [],
        "id": "a36a6e3f"
      },
      "source": [
        "Escribiendo archivos de películas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2b5d33",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:54.204733Z",
          "iopub.status.busy": "2021-11-16T19:32:54.203801Z",
          "iopub.status.idle": "2021-11-16T19:32:54.215330Z",
          "shell.execute_reply": "2021-11-16T19:32:54.216015Z",
          "shell.execute_reply.started": "2021-11-16T18:37:14.140888Z"
        },
        "papermill": {
          "duration": 0.078272,
          "end_time": "2021-11-16T19:32:54.216200",
          "exception": false,
          "start_time": "2021-11-16T19:32:54.137928",
          "status": "completed"
        },
        "tags": [],
        "id": "9b2b5d33"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/drive/MyDrive'\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26190ca8",
      "metadata": {
        "papermill": {
          "duration": 0.056832,
          "end_time": "2021-11-16T19:32:54.330330",
          "exception": false,
          "start_time": "2021-11-16T19:32:54.273498",
          "status": "completed"
        },
        "tags": [],
        "id": "26190ca8"
      },
      "source": [
        "Función para generar datos de entrenamiento y datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb0c51fb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:54.447576Z",
          "iopub.status.busy": "2021-11-16T19:32:54.446917Z",
          "iopub.status.idle": "2021-11-16T19:32:54.455114Z",
          "shell.execute_reply": "2021-11-16T19:32:54.455635Z",
          "shell.execute_reply.started": "2021-11-16T18:37:14.161356Z"
        },
        "papermill": {
          "duration": 0.068967,
          "end_time": "2021-11-16T19:32:54.455843",
          "exception": false,
          "start_time": "2021-11-16T19:32:54.386876",
          "status": "completed"
        },
        "tags": [],
        "id": "eb0c51fb"
      },
      "outputs": [],
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId') #Agrupando por usuario\n",
        "    tr_list, te_list = list(), list() \n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group) #numero de items por usuario\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f63ededc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:54.574977Z",
          "iopub.status.busy": "2021-11-16T19:32:54.574038Z",
          "iopub.status.idle": "2021-11-16T19:32:54.695013Z",
          "shell.execute_reply": "2021-11-16T19:32:54.694438Z",
          "shell.execute_reply.started": "2021-11-16T18:37:14.172368Z"
        },
        "papermill": {
          "duration": 0.182161,
          "end_time": "2021-11-16T19:32:54.695172",
          "exception": false,
          "start_time": "2021-11-16T19:32:54.513011",
          "status": "completed"
        },
        "tags": [],
        "id": "f63ededc"
      },
      "outputs": [],
      "source": [
        "#Ubicación usuarios para validación \n",
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "#Ubicación películas con usuarios de validación\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1d2596",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:32:54.814741Z",
          "iopub.status.busy": "2021-11-16T19:32:54.814058Z",
          "iopub.status.idle": "2021-11-16T19:33:03.275871Z",
          "shell.execute_reply": "2021-11-16T19:33:03.275231Z",
          "shell.execute_reply.started": "2021-11-16T18:37:14.316488Z"
        },
        "papermill": {
          "duration": 8.523469,
          "end_time": "2021-11-16T19:33:03.276021",
          "exception": false,
          "start_time": "2021-11-16T19:32:54.752552",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be1d2596",
        "outputId": "aa4193b3-52b2-4cbb-9b82-556c8cd1241b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ]
        }
      ],
      "source": [
        "#Dividiendo datos de peliculas de usuarios de validación en train y test data sets\n",
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf410a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:03.400992Z",
          "iopub.status.busy": "2021-11-16T19:33:03.400037Z",
          "iopub.status.idle": "2021-11-16T19:33:03.530361Z",
          "shell.execute_reply": "2021-11-16T19:33:03.531183Z",
          "shell.execute_reply.started": "2021-11-16T18:37:23.038857Z"
        },
        "papermill": {
          "duration": 0.194892,
          "end_time": "2021-11-16T19:33:03.531434",
          "exception": false,
          "start_time": "2021-11-16T19:33:03.336542",
          "status": "completed"
        },
        "tags": [],
        "id": "cdf410a3"
      },
      "outputs": [],
      "source": [
        "#Ubicación de usuarios en test data\n",
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "#Ubicación de items en test data\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b03aa83",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:03.659897Z",
          "iopub.status.busy": "2021-11-16T19:33:03.659285Z",
          "iopub.status.idle": "2021-11-16T19:33:12.176826Z",
          "shell.execute_reply": "2021-11-16T19:33:12.177317Z",
          "shell.execute_reply.started": "2021-11-16T18:37:23.161706Z"
        },
        "papermill": {
          "duration": 8.580206,
          "end_time": "2021-11-16T19:33:12.177530",
          "exception": false,
          "start_time": "2021-11-16T19:33:03.597324",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b03aa83",
        "outputId": "e89ac57f-c2ef-4143-fcdd-8d973bc0d6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ]
        }
      ],
      "source": [
        "#Dividiendo datos de peliculas de usuarios de los datos de prueba (test sets) en train y test data sets\n",
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a1f2d07",
      "metadata": {
        "papermill": {
          "duration": 0.062539,
          "end_time": "2021-11-16T19:33:12.303210",
          "exception": false,
          "start_time": "2021-11-16T19:33:12.240671",
          "status": "completed"
        },
        "tags": [],
        "id": "9a1f2d07"
      },
      "source": [
        "Guardando los datos en formato user_index e item_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00a9f3a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:12.436223Z",
          "iopub.status.busy": "2021-11-16T19:33:12.435614Z",
          "iopub.status.idle": "2021-11-16T19:33:12.441390Z",
          "shell.execute_reply": "2021-11-16T19:33:12.441916Z",
          "shell.execute_reply.started": "2021-11-16T18:37:31.189867Z"
        },
        "papermill": {
          "duration": 0.076086,
          "end_time": "2021-11-16T19:33:12.442077",
          "exception": false,
          "start_time": "2021-11-16T19:33:12.365991",
          "status": "completed"
        },
        "tags": [],
        "id": "e00a9f3a"
      },
      "outputs": [],
      "source": [
        "def numerize(data):\n",
        "    uid = list(map(lambda x: profile2id[x], data['userId']))\n",
        "    sid = list(map(lambda x: show2id[x],   data['movieId']))\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f326b7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:12.575869Z",
          "iopub.status.busy": "2021-11-16T19:33:12.574909Z",
          "iopub.status.idle": "2021-11-16T19:33:39.896879Z",
          "shell.execute_reply": "2021-11-16T19:33:39.897368Z",
          "shell.execute_reply.started": "2021-11-16T18:37:31.198092Z"
        },
        "papermill": {
          "duration": 27.388128,
          "end_time": "2021-11-16T19:33:39.897595",
          "exception": false,
          "start_time": "2021-11-16T19:33:12.509467",
          "status": "completed"
        },
        "tags": [],
        "id": "16f326b7"
      },
      "outputs": [],
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82c1178",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:40.028153Z",
          "iopub.status.busy": "2021-11-16T19:33:40.027158Z",
          "iopub.status.idle": "2021-11-16T19:33:41.949411Z",
          "shell.execute_reply": "2021-11-16T19:33:41.949942Z",
          "shell.execute_reply.started": "2021-11-16T18:37:53.308416Z"
        },
        "papermill": {
          "duration": 1.989366,
          "end_time": "2021-11-16T19:33:41.950134",
          "exception": false,
          "start_time": "2021-11-16T19:33:39.960768",
          "status": "completed"
        },
        "tags": [],
        "id": "a82c1178"
      },
      "outputs": [],
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18573d1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:42.091972Z",
          "iopub.status.busy": "2021-11-16T19:33:42.086318Z",
          "iopub.status.idle": "2021-11-16T19:33:42.557698Z",
          "shell.execute_reply": "2021-11-16T19:33:42.557003Z",
          "shell.execute_reply.started": "2021-11-16T18:37:55.221669Z"
        },
        "papermill": {
          "duration": 0.543826,
          "end_time": "2021-11-16T19:33:42.557863",
          "exception": false,
          "start_time": "2021-11-16T19:33:42.014037",
          "status": "completed"
        },
        "tags": [],
        "id": "a18573d1"
      },
      "outputs": [],
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb22aac1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:42.686190Z",
          "iopub.status.busy": "2021-11-16T19:33:42.685258Z",
          "iopub.status.idle": "2021-11-16T19:33:44.591192Z",
          "shell.execute_reply": "2021-11-16T19:33:44.590512Z",
          "shell.execute_reply.started": "2021-11-16T18:37:55.484674Z"
        },
        "papermill": {
          "duration": 1.971212,
          "end_time": "2021-11-16T19:33:44.591328",
          "exception": false,
          "start_time": "2021-11-16T19:33:42.620116",
          "status": "completed"
        },
        "tags": [],
        "id": "eb22aac1"
      },
      "outputs": [],
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b073163",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:44.726760Z",
          "iopub.status.busy": "2021-11-16T19:33:44.718986Z",
          "iopub.status.idle": "2021-11-16T19:33:45.190073Z",
          "shell.execute_reply": "2021-11-16T19:33:45.190613Z",
          "shell.execute_reply.started": "2021-11-16T18:37:57.393606Z"
        },
        "papermill": {
          "duration": 0.536682,
          "end_time": "2021-11-16T19:33:45.190812",
          "exception": false,
          "start_time": "2021-11-16T19:33:44.654130",
          "status": "completed"
        },
        "tags": [],
        "id": "0b073163"
      },
      "outputs": [],
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n",
        "# print(test_data_te)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import tensorflow.compat.v2 as tf\n",
        "# from tensorflow.keras import l2, regularizers\n",
        "\n",
        "\n",
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.Variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.Variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])\n",
        "            "
      ],
      "metadata": {
        "id": "CoSiGY4gr7eu"
      },
      "id": "CoSiGY4gr7eu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        \n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.Variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.Variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.Variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.Variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "metadata": {
        "id": "sY9eeIc2r7rk"
      },
      "id": "sY9eeIc2r7rk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "metadata": {
        "id": "v5QQ5NyPr71Y"
      },
      "id": "v5QQ5NyPr71Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "metadata": {
        "id": "XfcQ77eVr7_s"
      },
      "id": "XfcQ77eVr7_s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "metadata": {
        "id": "-O5eDKGdtHGH"
      },
      "id": "-O5eDKGdtHGH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "metadata": {
        "id": "Rq0BK0WLtHT7"
      },
      "id": "Rq0BK0WLtHT7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "metadata": {
        "id": "ScKiJ1QbtHX_"
      },
      "id": "ScKiJ1QbtHX_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = range(N)\n",
        "\n",
        "# training batch size\n",
        "batch_size = 500\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = range(N_vad)\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "metadata": {
        "id": "MqyjqDArr8DW"
      },
      "id": "MqyjqDArr8DW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "metadata": {
        "id": "EIgEaofdtbRH"
      },
      "id": "EIgEaofdtbRH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "metadata": {
        "id": "cQ_Ccwuatbd6"
      },
      "id": "cQ_Ccwuatbd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "metadata": {
        "id": "8zRA8F1ZtblR"
      },
      "id": "8zRA8F1ZtblR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior() \n",
        "import tensorflow as tf2\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tW-GFLCtl46",
        "outputId": "1556feeb-8d2e-4eb3-a27c-c2bbd43dd5e6"
      },
      "id": "5tW-GFLCtl46",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"dropout/Mul:0\", shape=(?, 7550), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "metadata": {
        "id": "GC5IW0YytmAy"
      },
      "id": "GC5IW0YytmAy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = '/volmount/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "metadata": {
        "id": "GM3Xo-iMtmGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5532f26a-01bd-44d7-adc4-830dfaf15af1"
      },
      "id": "GM3Xo-iMtmGK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log directory: /volmount/log/ml-20m/VAE_anneal200.0K_cap2.0E-01/I-200-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "metadata": {
        "id": "nmzSjvA7tmIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fde553-5cbd-4d04-8be3-9f23a1e387c3"
      },
      "id": "nmzSjvA7tmIj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/VAE_anneal200.0K_cap2.0E-01/I-200-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 200"
      ],
      "metadata": {
        "id": "pqXb6EAqtmLQ"
      },
      "id": "pqXb6EAqtmLQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUMrUVKw_LD5",
        "outputId": "1c5bf183-0a95-41e8-e507-512c33599559"
      },
      "id": "TUMrUVKw_LD5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0-dev20220315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CPU only\n",
        "# !pip install tf-nightly  \n",
        "\n",
        "# # For GPU support\n",
        "# !pip install -U tf-nightly-gpu\n",
        "# saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "ndcgs_vad = []\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        # merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        # sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "        # summary_writer.add_summary(merged_valid, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHvsMn4l8G0p",
        "outputId": "ab6c7e51-1f6d-4934-b85f-8dd2d8105f6d"
      },
      "id": "sHvsMn4l8G0p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "d10ImcFU8G5d",
        "outputId": "ef3a08cd-1564-46a3-dae2-38d69fe5cfa0"
      },
      "id": "d10ImcFU8G5d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "metadata": {
        "id": "pA45Nu-08G9p"
      },
      "id": "pA45Nu-08G9p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "metadata": {
        "id": "hfIxbvIYXBEG"
      },
      "id": "hfIxbvIYXBEG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "kRSEYDv4dS0g",
        "outputId": "00ced11d-70e8-4d66-b147-bc2385b13f9d"
      },
      "id": "kRSEYDv4dS0g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-1fc262ee309c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1yShThwdLUz",
        "outputId": "074e4fe0-2cd2-4cdf-8198-dfa78d300777"
      },
      "id": "u1yShThwdLUz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/VAE_anneal200.0K_cap2.0E-01/I-200-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoDSdKifXBRd",
        "outputId": "afb6b954-b072-4bd4-bd4b-1daca1e835f0"
      },
      "id": "yoDSdKifXBRd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpEGS_OvXBhk",
        "outputId": "034b2532-e8d7-455c-8a7c-98feca1cbb89"
      },
      "id": "fpEGS_OvXBhk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test NDCG@100=nan (nan)\n",
            "Test Recall@20=nan (nan)\n",
            "Test Recall@50=nan (nan)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_dims = [200, n_items]"
      ],
      "metadata": {
        "id": "GnY4u5IlePnp"
      },
      "id": "GnY4u5IlePnp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "PE-5pZUgePvg",
        "outputId": "33ed326b-3dac-471d-dc75-160b272bf2ae"
      },
      "id": "PE-5pZUgePvg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-8e1050bac578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiDAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m98765\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-a9f4780bed4e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, p_dims, q_dims, lam, lr, random_seed)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-a9f4780bed4e>\u001b[0m in \u001b[0;36mconstruct_placeholders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         self.input_ph = tf.placeholder(\n\u001b[0m\u001b[1;32m     25\u001b[0m             dtype=tf.float32, shape=[None, self.dims[0]])\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder_with_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5X9HkphDePys"
      },
      "id": "5X9HkphDePys",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndcgs_vad = []\n",
        "i=0\n",
        "with tf.compat.v1.Session() as sess:\n",
        "\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        i+=1\n",
        "        idxlist = random.sample(list(idxlist), len(list(idxlist)))\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            #print(\"X: \",st_idx,end_idx)\n",
        "            #print(type(train_data))\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')  \n",
        "            #print(X.shape)\n",
        "            feed_dict = {dae.input_ph: X, \n",
        "                         dae.keep_prob_ph: 0.5} \n",
        "            #print(feed_dict)\n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                #summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "#            print()\n",
        "            X = val_data_train[idxlist_vad[st_idx:end_idx]]\n",
        "            #print(\"X\",X)\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "            #print(type(X))\n",
        "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            #print(\"Validation: \",NDCG_binary_at_k_batch(pred_val, val_data_test[idxlist_vad[st_idx:end_idx]]))\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, val_data_test[idxlist_vad[st_idx:end_idx]]))\n",
        "            #print(\"List: \", ndcg_dist)\n",
        "        print(\"Iteración: \", i )\n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_dist = np.nan_to_num(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        print(\"Mean: \", ndcg_)\n",
        "        ndcgs_vad.append(ndcg_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "kb0c1rOj8HAG",
        "outputId": "96a56791-11f0-47e8-9ba1-c841d1cb4fc7"
      },
      "id": "kb0c1rOj8HAG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-1d2cf4e9c0ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m#print(X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             feed_dict = {dae.input_ph: X, \n\u001b[0m\u001b[1;32m     24\u001b[0m                          dae.keep_prob_ph: 0.5} \n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#print(feed_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dae' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GeBr9Oyk8HD0"
      },
      "id": "GeBr9Oyk8HD0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9e372af6",
      "metadata": {
        "papermill": {
          "duration": 0.062016,
          "end_time": "2021-11-16T19:33:45.316992",
          "exception": false,
          "start_time": "2021-11-16T19:33:45.254976",
          "status": "completed"
        },
        "tags": [],
        "id": "9e372af6"
      },
      "source": [
        "# **DEFINICIÓN Y ENTRENAMIENTO DEL MODELO**\n",
        "\n",
        "**Notación:**\n",
        "Sea $u\\in \\{1,...,U\\}$ los índices de los usuarios e $i\\in\\{1,...,I\\}$ los índices de ítems. La matriz de interacción usuario-ítem es $X\\in\\mathbb{N}^{U\\times I}$. La matriz de interacción es binarizada.\n",
        "\n",
        "**Proceso generativo:**\n",
        "Para cada usuario $u$, el modelo empieza por muestrear la representación latente $K$-dimensional $\\mathbf{z}_u$ de una a priori Gaussiana estándar. La representación latente $\\mathbf{z}_u$ es transformada por una función no lineal $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ para producir una distribución de probabilidad sobre $I$ ítems $\\pi (\\mathbf{z}_u)$ del cual el historial de interacción $\\mathbf{x}_u$ se asume que es\n",
        "$$\n",
        "\\mathbf{z}_{u} \\sim \\mathscr{N}\\left(0, \\mathbf{I}_{K}\\right), \\pi\\left(\\mathbf{z}_{u}\\right) \\propto \\exp \\left\\{f_{\\theta}\\left(\\mathbf{z}_{u}\\right)\\}, \\mathbf{x}_{u} \\sim \\operatorname{Mult}\\left(N_{u}, \\pi\\left(\\mathbf{z}_{u}\\right)\\right)\\right.\n",
        "$$\n",
        "El objetivo de Multi-DAE para un solo usuario $u$ es:\n",
        "$$\n",
        "\\mathscr{L}_{u}(\\theta, \\phi)=\\log p_{\\theta}\\left(\\mathbf{x}_{u} \\mid g_{\\phi}\\left(\\mathbf{x}_{u}\\right)\\right)\n",
        "$$\n",
        "donde $g_{\\phi}(\\cdot)$ es la función \"encoder\" no-lineal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8597b445",
      "metadata": {
        "papermill": {
          "duration": 0.062043,
          "end_time": "2021-11-16T19:33:45.441165",
          "exception": false,
          "start_time": "2021-11-16T19:33:45.379122",
          "status": "completed"
        },
        "tags": [],
        "id": "8597b445"
      },
      "source": [
        "* The *Saver* class adds ops to save and restore variables to and from checkpoints. It also provides convenience methods to run these ops.\n",
        "* *tf.contrib.layers.xavier_initializer*: Draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71dd7ea4",
      "metadata": {
        "papermill": {
          "duration": 0.06193,
          "end_time": "2021-11-16T19:33:45.565187",
          "exception": false,
          "start_time": "2021-11-16T19:33:45.503257",
          "status": "completed"
        },
        "tags": [],
        "id": "71dd7ea4"
      },
      "source": [
        "# Multinomal Denoising Autoencoder Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5509a3e8",
      "metadata": {
        "papermill": {
          "duration": 0.062819,
          "end_time": "2021-11-16T19:33:45.690650",
          "exception": false,
          "start_time": "2021-11-16T19:33:45.627831",
          "status": "completed"
        },
        "tags": [],
        "id": "5509a3e8"
      },
      "source": [
        "**Autoencoders:**\n",
        "Un autoencoder toma como input valores $x\\in[0,1]^d$ y primero lo mapea (con un encoder) a una representación latente $h\\in[0,1]^{d^\\prime}$ mediante un mapeo determinista\n",
        "$$h=Wx+b,$$\n",
        "donde $W$ representa a la matriz de pesos y $b$ el vector de sesgos (biases). \n",
        "\n",
        "La representación latente $h$ es mapeada de vuelta (con el decoder) en una reconstrucción $z$ del mismo tamaño que $x$ mediante una transformación similar, es decir\n",
        "$$z= (W^\\prime h + b^\\prime).$$\n",
        "$z$ se debe ver como una predicción de $x$. La matriz de pesos $W^\\prime$ del mapeo inverso puede ser construido por $W^\\prime=W^T$.\n",
        "\n",
        "Buscamos \n",
        "$$\\min_\\theta\\|x-z\\|^2$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f36203f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:45.824142Z",
          "iopub.status.busy": "2021-11-16T19:33:45.817696Z",
          "iopub.status.idle": "2021-11-16T19:33:45.845749Z",
          "shell.execute_reply": "2021-11-16T19:33:45.845027Z",
          "shell.execute_reply.started": "2021-11-16T18:37:57.859780Z"
        },
        "papermill": {
          "duration": 0.093067,
          "end_time": "2021-11-16T19:33:45.845897",
          "exception": false,
          "start_time": "2021-11-16T19:33:45.752830",
          "status": "completed"
        },
        "tags": [],
        "id": "6f36203f"
      },
      "outputs": [],
      "source": [
        "#Clase de funciones para MULTINOMIAL DENOISING AUTOENCODERS (MULT-DAE)\n",
        "class MultiDAE(object):\n",
        "    '''Argumentos:\n",
        "    p_dims = dimensión decoder,\n",
        "    q_dims = dimensión encoder,\n",
        "    lam    = parámetro de regularización\n",
        "    lr     = learning rate'''\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None: \n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0]  == p_dims[-1], \"Dimensión de Input y output deben ser iguales para autoencoders\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Dimensión latente para los desajustes p- y q- de la red.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims   = self.q_dims + self.p_dims[1:] \n",
        "\n",
        "        self.lam = lam\n",
        "        self.lr  = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        #Para variables de entrenamiento (PLACEHOLDER)\n",
        "        tf.compat.v1.disable_eager_execution()\n",
        "        self.input_ph     = tf.compat.v1.placeholder( dtype=tf.float32, shape=[None, self.dims[0]])#matriz\n",
        "        self.keep_prob_ph = tf.compat.v1.placeholder_with_default( 1.0, shape=None) #Devuelve un valor entre 0 y 1\n",
        "    #Representación latente\n",
        "    def forward_pass(self):\n",
        "        h = tf.compat.v1.nn.l2_normalize( self.input_ph, 1) #Norma L2 de una matriz... devuelve un vector de la misma longitud que el input\n",
        "        #Computes dropout: randomly sets elements to zero to prevent overfitting\n",
        "        h = tf.compat.v1.nn.dropout( h, self.keep_prob_ph ) #With probability rate elements of x are set to 0. \n",
        "        #The remaining elements are scaled up by 1.0 / (1 - rate), so that the expected value is preserved.\n",
        "        #(Para evitar overfitting) #construyo vector y \n",
        "        for i, (w,b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.compat.v1.matmul(h,w)+b #Representación latente \n",
        "            if i != len(self.weights)-1: #Para la última capa\n",
        "                h = tf.compat.v1.nn.tanh(h) #Función de activación\n",
        "        return tf.compat.v1.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "        #Construyendo weights\n",
        "        self.weights = []\n",
        "        self.biases  = []\n",
        "        #Defino pesos\n",
        "        for i, (d_in,d_out) in enumerate(zip(self.dims[:-1],self.dims[1:])): #Enumera dims de encoder y decoder \n",
        "            weight_key = \"Weight_{}to_{}\".format(i,i+1) #Nombres\n",
        "            bias_key   = \"Bias_{}\".format(i+1)\n",
        "            #Creando nuevas variables (weights) con tensorflow\n",
        "            #Matriz de pesos\n",
        "            self.weights.append(tf.compat.v1.get_variable( name = weight_key, shape = [d_in, d_out],\n",
        "                                          initializer = tf.keras.initializers.glorot_normal(seed = self.random_seed)))\n",
        "            #Vector de sesgos\n",
        "            self.biases.append(tf.compat.v1.get_variable( name = bias_key, shape = [d_out],\n",
        "                                          initializer = tf.compat.v1.truncated_normal_initializer(stddev=0.001,\n",
        "                                                                                        seed = self.random_seed)))\n",
        "            #Agregando resumen estadístico\n",
        "            tf.compat.v1.summary.histogram( weight_key, self.weights[-1])\n",
        "            tf.compat.v1.summary.histogram( bias_key, self.biases[-1])\n",
        "    def loss(self):\n",
        "        with tf.GradientTape() as tape:\n",
        "            with tf.compat.v1.Session() as sess:\n",
        "                saver, logits = self.forward_pass()\n",
        "                log_softmax_var = tf.compat.v1.nn.log_softmax(logits)\n",
        "                neg_ll = -tf.compat.v1.reduce_mean(tf.reduce_sum(log_softmax_var * self.input_ph, axis=1))\n",
        "                reg_var = tf.compat.v1.nn.l2_loss(self.lam)\n",
        "                return neg_ll + 2.0 * reg_var\n",
        "        train_op = tf.optimizers.Adam(self.lr).minimize(loss, var_list=[self.weights,self.biases])\n",
        "        return train_op\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.compat.v1.nn.log_softmax(logits)\n",
        "        neg_ll = -tf.compat.v1.reduce_mean(tf.compat.v1.reduce_sum(log_softmax_var * self.input_ph, axis=1))\n",
        "        reg_var = tf.add_n([ tf.nn.l2_loss(v) for v in self.weights ])\n",
        "        print(np.shape(self.weights))\n",
        "        loss    = neg_ll + 2.0 * reg_var \n",
        "        train_op = tf.compat.v1.train.AdamOptimizer(self.lr).minimize(loss)#self.loss()\n",
        "        #train_op = tf.optimizers.Adam(self.lr).minimize(loss, var_list=[self.weights,self.biases])\n",
        "        # add summary statistics\n",
        "        tf.compat.v1.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.compat.v1.summary.scalar('loss', loss)\n",
        "        merged = tf.compat.v1.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0023f41e",
      "metadata": {
        "papermill": {
          "duration": 0.061768,
          "end_time": "2021-11-16T19:33:45.969779",
          "exception": false,
          "start_time": "2021-11-16T19:33:45.908011",
          "status": "completed"
        },
        "tags": [],
        "id": "0023f41e"
      },
      "source": [
        "# Multinomial Variational Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "960f8dd2",
      "metadata": {
        "papermill": {
          "duration": 0.061848,
          "end_time": "2021-11-16T19:33:46.094524",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.032676",
          "status": "completed"
        },
        "tags": [],
        "id": "960f8dd2"
      },
      "source": [
        "La función objetivo de Multi-VAE$^{PR}$ (ELBO) para un usuario $u$ es:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "donde $q_\\phi$ es la distribución variacional aproximada (modelo de inferencia). $\\beta$ es el parámetro de control adicional. La función objetivo de un conjunto de datos es el promedio sobre todos los usuarios. Esto se puede entrenar casi de la misma manera que Multi-DAE gracias al truco de la reparametrización.\n",
        "\n",
        "Recordemos que la distancia Kullback-Leiber está definida por \n",
        "$$\n",
        "\\operatorname{KL}\\left(q\\left(\\mathrm{z}_{u}\\right) \\| p\\left(\\mathrm{z}_{u} \\mid \\mathrm{x}_{u}\\right)\\right)=\\int_{-\\infty}^{\\infty} q\\left(\\mathrm{z}_{u}\\right) \\ln \\frac{q\\left(\\mathrm{z}_{u}\\right)}{p\\left(\\mathrm{z}_{u} \\mid \\mathrm{x}_{u}\\right)} \\mathrm{d} z_{u}\n",
        "$$\n",
        "\n",
        "Asumiendo que tenemos dos distribuciones con parámetros\n",
        " $q(z_u) \\sim N\\left(\\mu_u,diag\\{ \\sigma^{2}_u\\}\\right)$ y $p(z_u) \\sim N(0,I_K)$.\n",
        " \n",
        " Para agregar un poco más de contexto en términos de modelos de variables latentes, intentamos ajustar una posterior aproximada a la posterior verdadera minimizando la divergencia KL. Sea $ z_u $ la variable latente, $q(z_u)$ es la distribución aproximada y $ p(z_u) $ la distribución a priori. Los parámetros de $q$ son la salida del encoder.\n",
        "\n",
        "La divergencia KL para distribuciones Gaussianas es \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "K L(q \\| p) &=\\frac{1}{2} \\log (2 \\pi)+\\frac{1}{2}\\left(\\mu^{2}+\\sigma^{2}\\right)-\\frac{1}{2} \\log (2 \\pi)-\\frac{1}{2} \\log \\left(\\sigma^{2}\\right)-\\frac{1}{2} \\\\\n",
        "&=-\\frac{1}{2}\\left(1+\\log \\left(\\sigma^{2}\\right)+-\\mu^{2}-\\sigma^{2}\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "La ecuación anterior se puede generalizar al caso multivariado, sumando sobre todas las dimensiones, i.e.,\n",
        "$$\n",
        "K L(q \\| p)=-\\frac{1}{2} \\sum_{d=1}^{D}\\left(1+\\log \\left(\\sigma_u^{2}\\right)+-\\mu_u^{2}-\\sigma_u^{2}\\right)\n",
        "$$\n",
        "\n",
        "Para la divergencia KL ver\n",
        "https://leenashekhar.github.io/2019-01-30-KL-Divergence/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2bd6ae1",
      "metadata": {
        "papermill": {
          "duration": 0.061544,
          "end_time": "2021-11-16T19:33:46.217835",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.156291",
          "status": "completed"
        },
        "tags": [],
        "id": "f2bd6ae1"
      },
      "source": [
        "q_dims = dimensión de las capas del encoder \n",
        "$\\mu=x_{ui}[:,:qdims[-1]]$, $qdims[-1]$ dimensión de la última capa del encoder\n",
        "\n",
        "$\\log(var)=x_{ui}[:,qdims[-1]:]$\n",
        "\n",
        "$\\sigma = e^{0.5*\\log(var)}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab9f44ed",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:46.346120Z",
          "iopub.status.busy": "2021-11-16T19:33:46.345084Z",
          "iopub.status.idle": "2021-11-16T19:33:46.378771Z",
          "shell.execute_reply": "2021-11-16T19:33:46.378181Z",
          "shell.execute_reply.started": "2021-11-16T18:37:57.892163Z"
        },
        "papermill": {
          "duration": 0.099051,
          "end_time": "2021-11-16T19:33:46.378910",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.279859",
          "status": "completed"
        },
        "tags": [],
        "id": "ab9f44ed"
      },
      "outputs": [],
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "    def construct_placeholders(self):#Construyendo variables\n",
        "        super(MultiVAE, self).construct_placeholders() #Esta función nos permite invocar y \n",
        "        #conservar un método o atributo de una clase padre (primaria) desde una clase hija (secundaria) \n",
        "        #sin tener que nombrarla explícitamente.\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.compat.v1.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.compat.v1.placeholder_with_default(1., shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.compat.v1.nn.log_softmax(logits) #Función de activación \n",
        "        neg_ll = -tf.compat.v1.reduce_mean(tf.reduce_sum(log_softmax_var*self.input_ph,axis=-1))\n",
        "        #Aplicando regularización a los pesos\n",
        "        reg_var = tf.add_n([ tf.nn.l2_loss(v) for v in (self.weights_q + self.weights_p) ])\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2.0 * reg_var #'''Ecuación 5  ¿Por qué suma esto 2 * reg_var?'''\n",
        "        #Optimizando parametros \n",
        "        train_op = tf.compat.v1.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        #Resumen estadísticos\n",
        "        tf.compat.v1.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.compat.v1.summary.scalar('KL', KL)\n",
        "        tf.compat.v1.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.compat.v1.summary.merge_all() #Juntando todos los resúmenes estadísticos\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "\n",
        "\n",
        "#Redes\n",
        "    def q_graph(self): #encoder\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        h = tf.compat.v1.nn.l2_normalize( self.input_ph, 1)\n",
        "        h = tf.compat.v1.nn.dropout( h, self.keep_prob_ph )\n",
        "        print(h)\n",
        "        for i, (w,b) in enumerate(zip(self.weights_q,self.biases_q)): \n",
        "            #print(\"W\", w)\n",
        "            #print(\"b: \", b)\n",
        "            #print(\"Hereee: \", tf.compat.v1.matmul(h,w)) #HERE IS THE PROBLEM \n",
        "            h = tf.compat.v1.matmul(h,w) + b\n",
        "            \n",
        "            if i != len(self.weights_q)-1:\n",
        "                h = tf.compat.v1.nn.tanh(h)\n",
        "                \n",
        "            else: \n",
        "                #Se duplica la dimensión de la última capa del encoder (q_dims)\n",
        "                mu_q     = h[:,:self.q_dims[-1]] #Matriz de medias xiu[:,:dim_out] dim_out del encoder\n",
        "                logvar_q = h[:,self.q_dims[-1]:] \n",
        "                std_q    = tf.exp(0.5*logvar_q)\n",
        "                KL       = tf.compat.v1.reduce_mean(tf.reduce_sum(0.5*(-logvar_q+tf.exp(logvar_q)+mu_q**2-1),\n",
        "                                                            axis = 1))\n",
        "        return mu_q, std_q, KL\n",
        "    def p_graph(self,z): #decoder\n",
        "        h = z\n",
        "        for i, (w,b) in enumerate(zip(self.weights_p,self.biases_p)):\n",
        "            h = tf.compat.v1.matmul(h,w)+b #Matriz de representacion latente\n",
        "            if i != len(self.weights_p)-1:\n",
        "                h = tf.compat.v1.nn.tanh(h)\n",
        "        return h\n",
        "    def forward_pass(self): #Latent space\n",
        "        #q-network\n",
        "        #print(\"here\")\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        #print(tf.shape(std_q))\n",
        "        epsilon         = tf.random.normal(tf.shape(std_q)) #Epsilon aleatorio \n",
        "        sampled_z       = mu_q + self.is_training_ph*\\\n",
        "            epsilon*std_q #Reparametrización\n",
        "        #p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        return tf.compat.v1.train.Saver(), logits, KL #train.Saver guarda y restaura variables\n",
        "\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        #Construyendo weights encoder \n",
        "        self.weights_q = []\n",
        "        self.biases_q  = []\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1],self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1])-1:#penúltima capa para el conjunto de parámetros (media y varianza)\n",
        "                d_out *= 2\n",
        "            weight_key = \"Weight_q_{}_to{}\".format(i,i+1)\n",
        "            bias_key   = \"Bias_q_{}\".format(i+1)\n",
        "\n",
        "            self.weights_q.append(tf.compat.v1.get_variable( name = weight_key, shape = [d_in, d_out],\n",
        "                            initializer = tf.keras.initializers.glorot_normal(seed = self.random_seed)))\n",
        "            self.biases_q.append(tf.compat.v1.get_variable( name = bias_key, shape = [d_out], \n",
        "                            initializer = tf.compat.v1.truncated_normal_initializer(stddev=0.001,\n",
        "                                                                                seed = self.random_seed)))\n",
        "        #Agregando resumen estadístico\n",
        "        tf.compat.v1.summary.histogram(weight_key, self.weights_q[-1])\n",
        "        tf.compat.v1.summary.histogram(bias_key, self.biases_q[-1])\n",
        "\n",
        "        #Construyendo weights decoder \n",
        "        self.weights_p = []\n",
        "        self.biases_p  = []\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1],self.p_dims[1:])):\n",
        "            weight_key = \"Weight_p_{}_to_{}\".format(i,i+1)\n",
        "            bias_key   = \"Bias_p_{}\".format(i+1)\n",
        "\n",
        "            self.weights_p.append(tf.compat.v1.get_variable( name = weight_key, shape = [d_in, d_out],\n",
        "                            initializer = tf.keras.initializers.glorot_normal(seed = self.random_seed)))\n",
        "            self.biases_p.append(tf.compat.v1.get_variable( name = bias_key, shape = [d_out], \n",
        "                            initializer = tf.compat.v1.truncated_normal_initializer(stddev=0.001,\n",
        "                                                                                seed = self.random_seed)))\n",
        "        #Agregando resumen estadístico\n",
        "        tf.compat.v1.summary.histogram(weight_key, self.weights_p[-1])\n",
        "        tf.compat.v1.summary.histogram(bias_key, self.biases_p[-1])\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8779244d",
      "metadata": {
        "papermill": {
          "duration": 0.061985,
          "end_time": "2021-11-16T19:33:46.503580",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.441595",
          "status": "completed"
        },
        "tags": [],
        "id": "8779244d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f96b535",
      "metadata": {
        "papermill": {
          "duration": 0.062047,
          "end_time": "2021-11-16T19:33:46.627878",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.565831",
          "status": "completed"
        },
        "tags": [],
        "id": "8f96b535"
      },
      "source": [
        "# Entrenamiento y Validación de datos, Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "121c2477",
      "metadata": {
        "papermill": {
          "duration": 0.062984,
          "end_time": "2021-11-16T19:33:46.753212",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.690228",
          "status": "completed"
        },
        "tags": [],
        "id": "121c2477"
      },
      "source": [
        "Cargamos los datos de entrenamiento y de validación preprocesados "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00387210",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:46.885456Z",
          "iopub.status.busy": "2021-11-16T19:33:46.884488Z",
          "iopub.status.idle": "2021-11-16T19:33:46.889971Z",
          "shell.execute_reply": "2021-11-16T19:33:46.890440Z",
          "shell.execute_reply.started": "2021-11-16T18:37:57.917315Z"
        },
        "papermill": {
          "duration": 0.074385,
          "end_time": "2021-11-16T19:33:46.890614",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.816229",
          "status": "completed"
        },
        "tags": [],
        "id": "00387210"
      },
      "outputs": [],
      "source": [
        "unique_sid = list()\n",
        "#Datos de películas (índices)\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e320ee86",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:47.020782Z",
          "iopub.status.busy": "2021-11-16T19:33:47.019833Z",
          "iopub.status.idle": "2021-11-16T19:33:47.025723Z",
          "shell.execute_reply": "2021-11-16T19:33:47.026266Z",
          "shell.execute_reply.started": "2021-11-16T18:37:57.941498Z"
        },
        "papermill": {
          "duration": 0.072729,
          "end_time": "2021-11-16T19:33:47.026489",
          "exception": false,
          "start_time": "2021-11-16T19:33:46.953760",
          "status": "completed"
        },
        "tags": [],
        "id": "e320ee86"
      },
      "outputs": [],
      "source": [
        "#Función para cargar datos de entrenamiento\n",
        "def load_train_data(file):\n",
        "    dat     = pd.read_csv(file)\n",
        "    n_users = dat['uid'].max()+1 #usuarios\n",
        "    \n",
        "    rows    = dat['uid']\n",
        "    cols    = dat['sid']\n",
        "    data    = sparse.csr_matrix((np.ones_like(rows),(rows, cols)),\n",
        "                               dtype = 'float64', shape=(n_users,n_items)) #convirtiendo en matriz sparse\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62635b12",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:47.155918Z",
          "iopub.status.busy": "2021-11-16T19:33:47.154965Z",
          "iopub.status.idle": "2021-11-16T19:33:49.104834Z",
          "shell.execute_reply": "2021-11-16T19:33:49.104238Z",
          "shell.execute_reply.started": "2021-11-16T18:37:57.955751Z"
        },
        "papermill": {
          "duration": 2.015824,
          "end_time": "2021-11-16T19:33:49.104999",
          "exception": false,
          "start_time": "2021-11-16T19:33:47.089175",
          "status": "completed"
        },
        "tags": [],
        "id": "62635b12"
      },
      "outputs": [],
      "source": [
        "#Cargando datos de entrenamiento \n",
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95995294",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:49.238290Z",
          "iopub.status.busy": "2021-11-16T19:33:49.237552Z",
          "iopub.status.idle": "2021-11-16T19:33:49.240623Z",
          "shell.execute_reply": "2021-11-16T19:33:49.241097Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.060340Z"
        },
        "papermill": {
          "duration": 0.072317,
          "end_time": "2021-11-16T19:33:49.241256",
          "exception": false,
          "start_time": "2021-11-16T19:33:49.168939",
          "status": "completed"
        },
        "tags": [],
        "id": "95995294"
      },
      "outputs": [],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d89e58",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:49.379602Z",
          "iopub.status.busy": "2021-11-16T19:33:49.378577Z",
          "iopub.status.idle": "2021-11-16T19:33:49.381107Z",
          "shell.execute_reply": "2021-11-16T19:33:49.381717Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.069476Z"
        },
        "papermill": {
          "duration": 0.075742,
          "end_time": "2021-11-16T19:33:49.381897",
          "exception": false,
          "start_time": "2021-11-16T19:33:49.306155",
          "status": "completed"
        },
        "tags": [],
        "id": "27d89e58"
      },
      "outputs": [],
      "source": [
        "#Función para cargar datos de validación\n",
        "def load_tr_te_data(file_tr,file_te):\n",
        "    dat_tr = pd.read_csv(file_tr)\n",
        "    dat_te = pd.read_csv(file_te)\n",
        "    #Rango de índices de items\n",
        "    start_idx = min(dat_tr['uid'].min(),dat_te['uid'].min())\n",
        "    end_idx   = max(dat_tr['uid'].max(),dat_te['uid'].max())\n",
        "    \n",
        "    rows_train = dat_tr['uid']-start_idx\n",
        "    cols_train = dat_tr['sid']\n",
        "    \n",
        "    rows_test  = dat_te['uid']-start_idx\n",
        "    cols_test  = dat_te['sid']\n",
        "    \n",
        "    data_train = sparse.csr_matrix((np.ones_like(rows_train),(rows_train, cols_train)),\n",
        "                               dtype = 'float64', shape=(end_idx-start_idx+1,n_items)) #convirtiendo en matriz sparse\n",
        "    data_test  = sparse.csr_matrix((np.ones_like(rows_test),(rows_test, cols_test)),\n",
        "                               dtype = 'float64', shape=(end_idx-start_idx+1,n_items)) #convirtiendo en matriz sparse\n",
        "    return data_train, data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2347a5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:49.511339Z",
          "iopub.status.busy": "2021-11-16T19:33:49.510691Z",
          "iopub.status.idle": "2021-11-16T19:33:49.692839Z",
          "shell.execute_reply": "2021-11-16T19:33:49.693307Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.084640Z"
        },
        "papermill": {
          "duration": 0.248627,
          "end_time": "2021-11-16T19:33:49.693501",
          "exception": false,
          "start_time": "2021-11-16T19:33:49.444874",
          "status": "completed"
        },
        "tags": [],
        "id": "df2347a5"
      },
      "outputs": [],
      "source": [
        "#Cargando datos de validacion\n",
        "\n",
        "val_data_train,val_data_test = load_tr_te_data(os.path.join(pro_dir,'validation_tr.csv'),\n",
        "                                               os.path.join(pro_dir,'validation_te.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfaecf4e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:49.828970Z",
          "iopub.status.busy": "2021-11-16T19:33:49.828299Z",
          "iopub.status.idle": "2021-11-16T19:33:49.832693Z",
          "shell.execute_reply": "2021-11-16T19:33:49.833292Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.321008Z"
        },
        "papermill": {
          "duration": 0.071815,
          "end_time": "2021-11-16T19:33:49.833466",
          "exception": false,
          "start_time": "2021-11-16T19:33:49.761651",
          "status": "completed"
        },
        "tags": [],
        "id": "bfaecf4e"
      },
      "outputs": [],
      "source": [
        "type(val_data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea2cc18",
      "metadata": {
        "papermill": {
          "duration": 0.062494,
          "end_time": "2021-11-16T19:33:49.958912",
          "exception": false,
          "start_time": "2021-11-16T19:33:49.896418",
          "status": "completed"
        },
        "tags": [],
        "id": "1ea2cc18"
      },
      "source": [
        "Hiperparámetros de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48095a2a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:50.092438Z",
          "iopub.status.busy": "2021-11-16T19:33:50.088893Z",
          "iopub.status.idle": "2021-11-16T19:33:50.099638Z",
          "shell.execute_reply": "2021-11-16T19:33:50.100084Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.330093Z"
        },
        "papermill": {
          "duration": 0.077058,
          "end_time": "2021-11-16T19:33:50.100262",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.023204",
          "status": "completed"
        },
        "tags": [],
        "id": "48095a2a"
      },
      "outputs": [],
      "source": [
        "train_data = train_data[:10000,:]\n",
        "N = train_data.shape[0] #115308 observaciones\n",
        "idxlist = range(N) #Rango de indices\n",
        "\n",
        "#Batch size (entrenamiento)\n",
        "batch_size = 500\n",
        "val = np.ceil(float(N)/batch_size)\n",
        "batches_per_epoch = int(val)#función techo np.ceil\n",
        "\n",
        "#Parámetros de validación\n",
        "N_vad = val_data_train.shape[0] #observaciones\n",
        "idxlist_vad = range(N_vad)\n",
        "#Batch size para validación \n",
        "batch_size_vad = 2000\n",
        "\n",
        "#el número total de actualizaciones de gradiente para annealing\n",
        "total_anneal_steps = 200000\n",
        "#Annealing parámetro (más grande)\n",
        "anneal_cap = 0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c92b885",
      "metadata": {
        "papermill": {
          "duration": 0.062602,
          "end_time": "2021-11-16T19:33:50.226357",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.163755",
          "status": "completed"
        },
        "tags": [],
        "id": "0c92b885"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56ae555b",
      "metadata": {
        "papermill": {
          "duration": 0.063321,
          "end_time": "2021-11-16T19:33:50.352823",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.289502",
          "status": "completed"
        },
        "tags": [],
        "id": "56ae555b"
      },
      "source": [
        "**Discounted Cumulative Gain (DCG)** es la métrica para medir la calidad de la clasificación. Se utiliza principalmente en problemas de recuperación de información, como medir la eficacia del algoritmo del motor de búsqueda clasificando los artículos que muestra de acuerdo con su relevancia en términos de la palabra clave de búsqueda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc81f509",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:50.482270Z",
          "iopub.status.busy": "2021-11-16T19:33:50.481667Z",
          "iopub.status.idle": "2021-11-16T19:33:50.489295Z",
          "shell.execute_reply": "2021-11-16T19:33:50.489768Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.347503Z"
        },
        "papermill": {
          "duration": 0.073889,
          "end_time": "2021-11-16T19:33:50.489945",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.416056",
          "status": "completed"
        },
        "tags": [],
        "id": "dc81f509"
      },
      "outputs": [],
      "source": [
        "\n",
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b6cf7f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:50.618946Z",
          "iopub.status.busy": "2021-11-16T19:33:50.618322Z",
          "iopub.status.idle": "2021-11-16T19:33:50.624686Z",
          "shell.execute_reply": "2021-11-16T19:33:50.625213Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.362639Z"
        },
        "papermill": {
          "duration": 0.07246,
          "end_time": "2021-11-16T19:33:50.625393",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.552933",
          "status": "completed"
        },
        "tags": [],
        "id": "f3b6cf7f"
      },
      "outputs": [],
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e48ac9d",
      "metadata": {
        "papermill": {
          "duration": 0.066856,
          "end_time": "2021-11-16T19:33:50.755212",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.688356",
          "status": "completed"
        },
        "tags": [],
        "id": "8e48ac9d"
      },
      "source": [
        "**Entrenando un Multi-DAE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d761eda",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:50.906177Z",
          "iopub.status.busy": "2021-11-16T19:33:50.905507Z",
          "iopub.status.idle": "2021-11-16T19:33:50.908985Z",
          "shell.execute_reply": "2021-11-16T19:33:50.909595Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.381757Z"
        },
        "papermill": {
          "duration": 0.076659,
          "end_time": "2021-11-16T19:33:50.909764",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.833105",
          "status": "completed"
        },
        "tags": [],
        "id": "5d761eda"
      },
      "outputs": [],
      "source": [
        "p_dims = [200, n_items]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb11683a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:51.040130Z",
          "iopub.status.busy": "2021-11-16T19:33:51.039533Z",
          "iopub.status.idle": "2021-11-16T19:33:51.261525Z",
          "shell.execute_reply": "2021-11-16T19:33:51.261977Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.397766Z"
        },
        "papermill": {
          "duration": 0.288891,
          "end_time": "2021-11-16T19:33:51.262150",
          "exception": false,
          "start_time": "2021-11-16T19:33:50.973259",
          "status": "completed"
        },
        "tags": [],
        "id": "fb11683a"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.compat.v1.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "#merged_valid = tf.compat.v1.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff92d6e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:51.392809Z",
          "iopub.status.busy": "2021-11-16T19:33:51.392162Z",
          "iopub.status.idle": "2021-11-16T19:33:51.396615Z",
          "shell.execute_reply": "2021-11-16T19:33:51.397200Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.599708Z"
        },
        "papermill": {
          "duration": 0.071475,
          "end_time": "2021-11-16T19:33:51.397366",
          "exception": false,
          "start_time": "2021-11-16T19:33:51.325891",
          "status": "completed"
        },
        "tags": [],
        "id": "eff92d6e"
      },
      "outputs": [],
      "source": [
        "ndcg_dist_summary\n",
        "print(logits_var)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "453296da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:51.527509Z",
          "iopub.status.busy": "2021-11-16T19:33:51.526902Z",
          "iopub.status.idle": "2021-11-16T19:33:51.529820Z",
          "shell.execute_reply": "2021-11-16T19:33:51.530405Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.606190Z"
        },
        "papermill": {
          "duration": 0.069388,
          "end_time": "2021-11-16T19:33:51.530563",
          "exception": false,
          "start_time": "2021-11-16T19:33:51.461175",
          "status": "completed"
        },
        "tags": [],
        "id": "453296da"
      },
      "outputs": [],
      "source": [
        "n_epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3c248b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:33:51.661139Z",
          "iopub.status.busy": "2021-11-16T19:33:51.660505Z",
          "iopub.status.idle": "2021-11-16T19:55:46.115924Z",
          "shell.execute_reply": "2021-11-16T19:55:46.116658Z",
          "shell.execute_reply.started": "2021-11-16T18:38:00.618259Z"
        },
        "papermill": {
          "duration": 1314.522768,
          "end_time": "2021-11-16T19:55:46.116909",
          "exception": false,
          "start_time": "2021-11-16T19:33:51.594141",
          "status": "completed"
        },
        "tags": [],
        "id": "db3c248b"
      },
      "outputs": [],
      "source": [
        "ndcgs_vad = []\n",
        "i=0\n",
        "with tf.compat.v1.Session() as sess:\n",
        "\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        i+=1\n",
        "        idxlist = random.sample(list(idxlist), len(list(idxlist)))\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            #print(\"X: \",st_idx,end_idx)\n",
        "            #print(type(train_data))\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')  \n",
        "            #print(X.shape)\n",
        "            feed_dict = {dae.input_ph: X, \n",
        "                         dae.keep_prob_ph: 0.5} \n",
        "            #print(feed_dict)\n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                #summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "#            print()\n",
        "            X = val_data_train[idxlist_vad[st_idx:end_idx]]\n",
        "            #print(\"X\",X)\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "            #print(type(X))\n",
        "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            #print(\"Validation: \",NDCG_binary_at_k_batch(pred_val, val_data_test[idxlist_vad[st_idx:end_idx]]))\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, val_data_test[idxlist_vad[st_idx:end_idx]]))\n",
        "            #print(\"List: \", ndcg_dist)\n",
        "        print(\"Iteración: \", i )\n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_dist = np.nan_to_num(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        print(\"Mean: \", ndcg_)\n",
        "        ndcgs_vad.append(ndcg_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5b5cb5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:55:46.408231Z",
          "iopub.status.busy": "2021-11-16T19:55:46.371134Z",
          "iopub.status.idle": "2021-11-16T19:55:46.739600Z",
          "shell.execute_reply": "2021-11-16T19:55:46.738770Z",
          "shell.execute_reply.started": "2021-11-16T18:57:25.717960Z"
        },
        "papermill": {
          "duration": 0.49726,
          "end_time": "2021-11-16T19:55:46.739750",
          "exception": false,
          "start_time": "2021-11-16T19:55:46.242490",
          "status": "completed"
        },
        "tags": [],
        "id": "ca5b5cb5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0916e9e",
      "metadata": {
        "papermill": {
          "duration": 0.126358,
          "end_time": "2021-11-16T19:55:46.992940",
          "exception": false,
          "start_time": "2021-11-16T19:55:46.866582",
          "status": "completed"
        },
        "tags": [],
        "id": "a0916e9e"
      },
      "source": [
        "**Entrenamiento de MultiVAE**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3552219",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:55:47.249251Z",
          "iopub.status.busy": "2021-11-16T19:55:47.248637Z",
          "iopub.status.idle": "2021-11-16T19:55:47.689491Z",
          "shell.execute_reply": "2021-11-16T19:55:47.690055Z",
          "shell.execute_reply.started": "2021-11-16T18:57:26.003666Z"
        },
        "papermill": {
          "duration": 0.570287,
          "end_time": "2021-11-16T19:55:47.690223",
          "exception": false,
          "start_time": "2021-11-16T19:55:47.119936",
          "status": "completed"
        },
        "tags": [],
        "id": "c3552219"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "p_dims = [200, 600, n_items]\n",
        "#tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765) #Llama a la clase MultiVAE\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph() #Construccion del grafo\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.compat.v1.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "#merged_valid = tf.compat.v1.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa29ed2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:55:47.947868Z",
          "iopub.status.busy": "2021-11-16T19:55:47.947200Z",
          "iopub.status.idle": "2021-11-16T19:55:47.948794Z",
          "shell.execute_reply": "2021-11-16T19:55:47.949345Z",
          "shell.execute_reply.started": "2021-11-16T18:57:26.372985Z"
        },
        "papermill": {
          "duration": 0.13313,
          "end_time": "2021-11-16T19:55:47.949522",
          "exception": false,
          "start_time": "2021-11-16T19:55:47.816392",
          "status": "completed"
        },
        "tags": [],
        "id": "baa29ed2"
      },
      "outputs": [],
      "source": [
        "n_epochs = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c907a610",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T19:55:48.203318Z",
          "iopub.status.busy": "2021-11-16T19:55:48.202613Z",
          "iopub.status.idle": "2021-11-16T20:31:35.764021Z",
          "shell.execute_reply": "2021-11-16T20:31:35.764627Z",
          "shell.execute_reply.started": "2021-11-16T18:57:26.378990Z"
        },
        "papermill": {
          "duration": 2147.689996,
          "end_time": "2021-11-16T20:31:35.764847",
          "exception": false,
          "start_time": "2021-11-16T19:55:48.074851",
          "status": "completed"
        },
        "tags": [],
        "id": "c907a610"
      },
      "outputs": [],
      "source": [
        "ndcgs_vad = []\n",
        "i=0\n",
        "with tf.compat.v1.Session() as sess:\n",
        "\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        i+=1\n",
        "        idxlist = random.sample(list(idxlist), len(list(idxlist)))\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = val_data_train[idxlist_vad[st_idx:end_idx]]\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X,vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, val_data_test[idxlist_vad[st_idx:end_idx]]))\n",
        "        print(\"Iteración: \", i )\n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_dist = np.nan_to_num(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        print(\"Mean: \", ndcg_)\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d0ab01",
      "metadata": {
        "papermill": {
          "duration": 0.18639,
          "end_time": "2021-11-16T20:31:36.156083",
          "exception": false,
          "start_time": "2021-11-16T20:31:35.969693",
          "status": "completed"
        },
        "tags": [],
        "id": "39d0ab01"
      },
      "source": [
        "Medida del rendimiento medio del algoritmo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed3c3eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-16T20:31:36.534238Z",
          "iopub.status.busy": "2021-11-16T20:31:36.531432Z",
          "iopub.status.idle": "2021-11-16T20:31:36.843517Z",
          "shell.execute_reply": "2021-11-16T20:31:36.843976Z",
          "shell.execute_reply.started": "2021-11-16T19:28:17.719788Z"
        },
        "papermill": {
          "duration": 0.500993,
          "end_time": "2021-11-16T20:31:36.844145",
          "exception": false,
          "start_time": "2021-11-16T20:31:36.343152",
          "status": "completed"
        },
        "tags": [],
        "id": "7ed3c3eb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c56bd2a",
      "metadata": {
        "papermill": {
          "duration": 0.186253,
          "end_time": "2021-11-16T20:31:37.217394",
          "exception": false,
          "start_time": "2021-11-16T20:31:37.031141",
          "status": "completed"
        },
        "tags": [],
        "id": "3c56bd2a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3579.953913,
      "end_time": "2021-11-16T20:31:40.115871",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-11-16T19:32:00.161958",
      "version": "2.3.3"
    },
    "colab": {
      "name": "vaes-for-collaborative-filtering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}